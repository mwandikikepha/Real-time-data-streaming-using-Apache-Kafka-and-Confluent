# Real-time-data-streaming-using-Apache-Kafka-and-Confluent

This project demonstrates how to build a real-time data streaming pipeline using Apache Kafka and Confluent. It includes a producer that streams data into a Kafka topic and a consumer that listens and processes the data in real-time.

**🚀 What’s inside**

*confluent_prod.py* → A Kafka producer script that publishes messages/events into a Kafka topic.

*confluent_cons.py* → A Kafka consumer script that subscribes to the topic and processes messages as they arrive.

**🎯 Why this project?**

Real-time data is everywhere; from financial transactions, IoT devices, and ride-hailing apps to social media feeds. This project shows the fundamental building blocks behind those systems:

Streaming live data instead of batch data.

Decoupling systems with Kafka’s publish-subscribe model.

Leveraging Confluent’s ecosystem to simplify integration.

**🛠️ Tech Stack**

*Apache Kafka* – for distributed messaging and event streaming.

*Confluent Platform* – for client libraries and Kafka tooling.

*Python* – for writing producer and consumer logic.
